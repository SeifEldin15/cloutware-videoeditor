<template>
  <div class="min-h-screen bg-gray-900 text-white">
    <!-- Header -->
    <header class="bg-gray-800 border-b border-gray-700 p-6">
      <div class="max-w-7xl mx-auto">
        <h1 class="text-3xl font-bold text-blue-400">Complete Processing</h1>
        <p class="text-gray-300 mt-2">Upload, transcribe, add subtitles, and process videos all in one place</p>
      </div>
    </header>

    <!-- Main Content -->
    <main class="max-w-7xl mx-auto p-6">
      <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
        
        <!-- Left Panel: Input & Configuration -->
        <div class="space-y-6">
          
          <!-- Video Input Section -->
          <div class="bg-gray-800 rounded-lg p-6">
            <h2 class="text-xl font-semibold mb-4 text-blue-300">1. Video Input</h2>
            
            <!-- Video URL Input -->
            <div class="mb-4">
              <label class="block text-sm font-medium mb-2">Video URL</label>
              <input 
                v-model="videoUrl" 
                type="url" 
                placeholder="https://example.com/video.mp4"
                class="w-full px-3 py-2 bg-gray-700 border border-gray-600 rounded-md focus:ring-2 focus:ring-blue-500 focus:border-transparent"
              />
            </div>

            <!-- File Upload -->
            <div class="mb-4">
              <label class="block text-sm font-medium mb-2">Or Upload Video File</label>
              <div class="border-2 border-dashed border-gray-600 rounded-lg p-6 text-center hover:border-blue-500 transition-colors">
                <input 
                  type="file" 
                  accept="video/*" 
                  @change="handleFileUpload"
                  class="hidden" 
                  ref="fileInput"
                />
                <div @click="$refs.fileInput.click()" class="cursor-pointer">
                  <svg class="mx-auto h-12 w-12 text-gray-400" stroke="currentColor" fill="none" viewBox="0 0 48 48">
                    <path d="M28 8H12a4 4 0 00-4 4v20m32-12v8m0 0v8a4 4 0 01-4 4H12a4 4 0 01-4-4v-4m32-4l-3.172-3.172a4 4 0 00-5.656 0L28 28M8 32l9.172-9.172a4 4 0 015.656 0L28 28m0 0l4 4m4-24h8m-4-4v8m-12 4h.02" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" />
                  </svg>
                  <p class="mt-2 text-sm text-gray-400">
                    <span class="font-medium text-blue-400">Click to upload</span> or drag and drop
                  </p>
                  <p class="text-xs text-gray-500">MP4, MOV, AVI up to 500MB</p>
                </div>
              </div>
              
              <div v-if="uploadedFile" class="mt-2 text-sm text-green-400">
                ‚úì {{ uploadedFile.name }} ({{ Math.round(uploadedFile.size / 1024 / 1024) }}MB)
              </div>
            </div>
          </div>

          <!-- Transcription Settings -->
          <div class="bg-gray-800 rounded-lg p-6">
            <h2 class="text-xl font-semibold mb-4 text-blue-300">2. Transcription Settings</h2>
            
            <!-- Source Selection -->
            <div class="mb-4">
              <label class="block text-sm font-medium mb-2">Transcription Source</label>
              <div class="space-y-2">
                <label class="flex items-center">
                  <input v-model="transcriptionSettings.source" value="video-audio" type="radio" class="text-blue-600 bg-gray-700 border-gray-600 focus:ring-blue-500">
                  <span class="ml-2 text-sm">Extract from video audio (AI transcription)</span>
                </label>
                <label class="flex items-center">
                  <input v-model="transcriptionSettings.source" value="manual" type="radio" class="text-blue-600 bg-gray-700 border-gray-600 focus:ring-blue-500">
                  <span class="ml-2 text-sm">Manual text input</span>
                </label>
              </div>
            </div>

            <!-- Manual Text Input (when manual is selected) -->
            <div v-if="transcriptionSettings.source === 'manual'" class="mb-4">
              <label class="block text-sm font-medium mb-2">Manual Transcription Text</label>
              <textarea 
                v-model="transcriptionSettings.manualText"
                class="w-full h-32 px-3 py-2 bg-gray-700 border border-gray-600 rounded-md focus:ring-2 focus:ring-blue-500 focus:border-transparent resize-y"
                placeholder="Enter your text content here. This will be converted to subtitle format automatically."
              ></textarea>
            </div>

            <!-- AI Transcription Settings (when video-audio is selected) -->
            <div v-if="transcriptionSettings.source === 'video-audio'" class="space-y-4">
              <!-- Language Selection -->
              <div>
                <label class="block text-sm font-medium mb-2">Language</label>
                <select v-model="transcriptionSettings.language" class="w-full px-3 py-2 bg-gray-700 border border-gray-600 rounded-md focus:ring-2 focus:ring-blue-500">
                  <option value="en">English</option>
                  <option value="es">Spanish</option>
                  <option value="fr">French</option>
                  <option value="de">German</option>
                  <option value="it">Italian</option>
                  <option value="pt">Portuguese</option>
                  <option value="zh">Chinese</option>
                  <option value="ja">Japanese</option>
                  <option value="ko">Korean</option>
                  <option value="ar">Arabic</option>
                </select>
              </div>

              <!-- Advanced Options -->
              <div class="space-y-3">
                <label class="flex items-center">
                  <input v-model="transcriptionSettings.speakerLabels" type="checkbox" class="rounded bg-gray-700 border-gray-600 text-blue-600 focus:ring-blue-500">
                  <span class="ml-2 text-sm">Speaker labels</span>
                </label>
                <label class="flex items-center">
                  <input v-model="transcriptionSettings.punctuate" type="checkbox" class="rounded bg-gray-700 border-gray-600 text-blue-600 focus:ring-blue-500">
                  <span class="ml-2 text-sm">Auto punctuation</span>
                </label>
                <label class="flex items-center">
                  <input v-model="transcriptionSettings.formatText" type="checkbox" class="rounded bg-gray-700 border-gray-600 text-blue-600 focus:ring-blue-500">
                  <span class="ml-2 text-sm">Format text</span>
                </label>
              </div>
            </div>
          </div>

          <!-- Subtitle Settings -->
          <div class="bg-gray-800 rounded-lg p-6">
            <h2 class="text-xl font-semibold mb-4 text-blue-300">3. Subtitle Settings</h2>
            
            <!-- Style Selection -->
            <div class="mb-4">
              <label class="block text-sm font-medium mb-2">Animation Style Template</label>
              <select v-model="subtitleSettings.animationStyle" class="w-full px-3 py-2 bg-gray-700 border border-gray-600 rounded-md focus:ring-2 focus:ring-blue-500">
                <optgroup label="üî• Viral Templates">
                  <option value="girlboss">üíÖ Girlboss - Bold pink/purple animations</option>
                  <option value="hormozi">üöÄ Hormozi - Business motivational style</option>
                  <option value="tiktokstyle">üì± TikTok Style - Social media trending</option>
                </optgroup>
                <optgroup label="‚ö° Impact Templates">
                  <option value="whiteimpact">‚ö™ White Impact - Clean white highlights</option>
                  <option value="impactfull">üí• Impact Full - Maximum visual impact</option>
                  <option value="thinToBold">üìà Thin to Bold - Progressive emphasis</option>
                </optgroup>
                <optgroup label="üé® Creative Templates">
                  <option value="wavyColors">üåä Wavy Colors - Flowing rainbow effects</option>
                  <option value="revealEnlarge">üîç Reveal Enlarge - Zoom-in discovery</option>
                  <option value="shrinkingPairs">üìê Shrinking Pairs - Minimalist pairs</option>
                </optgroup>
              </select>
              
              <!-- Template Preview/Description -->
              <div class="mt-2 p-3 bg-gradient-to-r from-gray-700 to-gray-600 rounded-lg border border-gray-500">
                <div class="flex items-center justify-between mb-2">
                  <div class="font-medium text-blue-300">{{ getTemplateDescription(subtitleSettings.animationStyle) }}</div>
                  <div class="text-xs bg-blue-600 px-2 py-1 rounded-full">{{ subtitleSettings.animationStyle.toUpperCase() }}</div>
                </div>
                
                <!-- Template Preset Info -->
                <div class="mb-2 p-2 bg-blue-900/30 border border-blue-600 rounded">
                  <div class="flex items-center text-blue-400 text-xs">
                    <span class="mr-2">üé®</span>
                    <span class="font-medium">TEMPLATE PRESET LOADED</span>
                  </div>
                  <div class="text-blue-300 text-xs mt-1">
                    This template's optimized settings have been loaded as your starting point. Feel free to customize!
                  </div>
                </div>
                
                <div class="text-gray-300 text-xs mb-2">{{ getTemplateFeatures(subtitleSettings.animationStyle) }}</div>
                <div class="flex items-center justify-between">
                  <div class="text-xs text-gray-400">
                    üé® <span class="inline-block w-3 h-3 rounded-full ml-1" :style="{ backgroundColor: subtitleSettings.primaryColor }"></span>
                    <span class="inline-block w-3 h-3 rounded-full ml-1" :style="{ backgroundColor: subtitleSettings.secondaryColor }"></span>
                    ‚Ä¢ üìù {{ subtitleSettings.fontFamily }}
                  </div>
                  <div class="text-xs text-gray-400">{{ subtitleSettings.fontSize }}px ‚Ä¢ {{ subtitleSettings.wordMode }} ‚Ä¢ {{ subtitleSettings.verticalPosition }}</div>
                </div>
              </div>
            </div>

            <!-- Font Selection -->
            <div class="mb-4">
              <label class="block text-sm font-medium mb-2">
                Font Family
                <span class="text-xs text-blue-400 ml-2">‚ú® Template Suggested</span>
              </label>
              
              <!-- Always Editable Font Selection -->
              <select v-model="subtitleSettings.fontFamily" class="w-full px-3 py-2 bg-gray-700 border border-gray-600 rounded-md focus:ring-2 focus:ring-blue-500">
                <option value="Inter-Bold.ttf">Inter Bold</option>
                <option value="Roboto-Bold.ttf">Roboto Bold</option>
                <option value="Montserrat-Bold.ttf">Montserrat Bold</option>
                <option value="OpenSans-Bold.ttf">Open Sans Bold</option>
                <option value="Poppins-Bold.ttf">Poppins Bold</option>
                <option value="SourceSansPro-Bold.ttf">Source Sans Pro Bold</option>
              </select>
            </div>

            <!-- Colors -->
            <div class="mb-4">
              <div class="flex items-center justify-between mb-2">
                <label class="block text-sm font-medium">
                  Subtitle Colors
                  <span class="text-xs text-blue-400 ml-2">‚ú® Template Suggested</span>
                </label>
              </div>
              
              <!-- Always Editable Color Selection -->
              <div class="grid grid-cols-2 gap-4">
                <div>
                  <label class="block text-xs font-medium mb-1 text-gray-300">Primary Color</label>
                  <input v-model="subtitleSettings.primaryColor" type="color" class="w-full h-10 bg-gray-700 border border-gray-600 rounded-md">
                </div>
                <div>
                  <label class="block text-xs font-medium mb-1 text-gray-300">Secondary Color</label>
                  <input v-model="subtitleSettings.secondaryColor" type="color" class="w-full h-10 bg-gray-700 border border-gray-600 rounded-md">
                </div>
              </div>
              <div class="mt-2 text-xs text-blue-400">
                üé® Template colors loaded as starting point - customize as needed!
              </div>
            </div>

            <!-- Font Size -->
            <div class="mb-4">
              <label class="block text-sm font-medium mb-2">
                Font Size: {{ subtitleSettings.fontSize }}px
                <span class="text-xs text-blue-400 ml-2">‚ú® Template Suggested</span>
              </label>
              
              <!-- Always Editable Font Size -->
              <input v-model="subtitleSettings.fontSize" type="range" min="20" max="100" class="w-full">
              <div class="mt-1 text-xs text-blue-400">
                üìè Template optimized size loaded - adjust as needed!
              </div>
            </div>

            <!-- Vertical Position -->
            <div class="mb-4">
              <label class="block text-sm font-medium mb-2">
                Vertical Position
                <span class="text-xs text-blue-400 ml-2">‚ú® Template Suggested</span>
              </label>
              
              <!-- Always Editable Vertical Position -->
              <select v-model="subtitleSettings.verticalPosition" class="w-full px-3 py-2 bg-gray-700 border border-gray-600 rounded-md focus:ring-2 focus:ring-blue-500">
                <option value="top">üîù Top - Subtitles at the top of video</option>
                <option value="center">üéØ Center - Subtitles in the middle</option>
                <option value="bottom">üîΩ Bottom - Subtitles at the bottom (default)</option>
              </select>
              <div class="mt-1 text-xs text-blue-400">
                üìç Template position loaded - choose what works best for your video!
              </div>
            </div>

            <!-- Word Processing Settings -->
            <div class="mb-4">
              <div class="flex items-center justify-between mb-2">
                <label class="block text-sm font-medium">
                  Word Animation Mode
                  <span class="text-xs text-blue-400 ml-2">‚ú® Template Suggested</span>
                </label>
              </div>
              
              <!-- Always Editable Word Processing -->
              <select v-model="subtitleSettings.wordMode" class="w-full px-3 py-2 bg-gray-700 border border-gray-600 rounded-md focus:ring-2 focus:ring-blue-500 mb-2">
                <option value="normal">Normal - Full sentences</option>
                <option value="single">Single - One word at a time</option>
                <option value="multiple">Multiple - Word groups</option>
              </select>
              
              <div v-if="subtitleSettings.wordMode === 'multiple'" class="mt-2">
                <label class="block text-xs font-medium mb-1 text-gray-300">Words per Group: {{ subtitleSettings.wordsPerGroup }}</label>
                <input v-model="subtitleSettings.wordsPerGroup" type="range" min="1" max="6" class="w-full">
              </div>
              
              <div class="mt-2 text-xs text-blue-400">
                üéØ Template optimized settings loaded - customize for your style!
              </div>
            </div>
          </div>

          <!-- Processing Options -->
          <div class="bg-gray-800 rounded-lg p-6">
            <h2 class="text-xl font-semibold mb-4 text-blue-300">4. Processing Options</h2>
            
            <!-- Video Quality Selection -->
            <div class="mb-4">
              <label class="block text-sm font-medium mb-2">Video Quality</label>
              <select v-model="processingOptions.quality" class="w-full px-3 py-2 bg-gray-700 border border-gray-600 rounded-md focus:ring-2 focus:ring-blue-500">
                <option value="premium">üèÜ Premium - Near-lossless quality (CRF 12, slower preset)</option>
                <option value="high">‚≠ê High Quality - Professional grade (CRF 15, slow preset)</option>
                <option value="standard">üéØ Standard - Balanced quality (CRF 18, medium preset)</option>
                <option value="fast">‚ö° Fast - Quick processing (CRF 23, fast preset)</option>
              </select>
              <div class="mt-2 text-xs text-gray-400">
                Higher quality = larger file size and longer processing time
              </div>
            </div>
            
            <div class="space-y-3">
              <label class="flex items-center">
                <input v-model="processingOptions.generateSubtitles" type="checkbox" class="rounded bg-gray-700 border-gray-600 text-blue-600 focus:ring-blue-500">
                <span class="ml-2 text-sm">Generate subtitle files</span>
              </label>
              <label class="flex items-center">
                <input v-model="processingOptions.embedSubtitles" type="checkbox" class="rounded bg-gray-700 border-gray-600 text-blue-600 focus:ring-blue-500">
                <span class="ml-2 text-sm">Embed subtitles in video</span>
              </label>
              <label class="flex items-center">
                <input v-model="processingOptions.optimizeForWeb" type="checkbox" class="rounded bg-gray-700 border-gray-600 text-blue-600 focus:ring-blue-500">
                <span class="ml-2 text-sm">Optimize for web playback</span>
              </label>
            </div>
          </div>

          <!-- Action Buttons -->
          <div class="bg-gray-800 rounded-lg p-6">
            <div class="flex space-x-4">
              <button 
                @click="startTranscription"
                :disabled="!canStartTranscription || isProcessing"
                class="flex-1 bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 disabled:cursor-not-allowed px-4 py-3 rounded-md font-medium transition-colors"
              >
                <span v-if="isTranscribing">{{ transcriptionSettings.source === 'video-audio' ? 'Extracting & Transcribing...' : 'Processing...' }}</span>
                <span v-else>{{ transcriptionSettings.source === 'video-audio' ? 'Extract Audio & Transcribe' : 'Use Manual Transcription' }}</span>
              </button>
              
              <button 
                @click="processVideo"
                :disabled="!canProcessVideo || isProcessing"
                class="flex-1 bg-green-600 hover:bg-green-700 disabled:bg-gray-600 disabled:cursor-not-allowed px-4 py-3 rounded-md font-medium transition-colors"
              >
                {{ isProcessingVideo ? 'Processing...' : !results.transcription ? 'Run Transcription First' : 'Process Video' }}
              </button>
            </div>
            
            <!-- Debug Info -->
            <div class="mt-4 p-3 bg-gray-700 rounded text-xs">
              <div><strong>Debug:</strong></div>
              <div>Has transcription: {{ !!results.transcription }}</div>
              <div>Transcription length: {{ results.transcription?.length || 0 }}</div>
              <div>Is transcribing: {{ isTranscribing }}</div>
              <div>Processing steps completed: {{ processingSteps.filter(s => s.status === 'completed').length }}/{{ processingSteps.length }}</div>
              <button @click="testTranscription" class="mt-2 px-2 py-1 bg-purple-600 rounded text-xs">Test Set Transcription</button>
              <button @click="testAPI" class="mt-2 ml-2 px-2 py-1 bg-yellow-600 rounded text-xs">Test API</button>
            </div>
          </div>
        </div>

        <!-- Right Panel: Preview & Results -->
        <div class="space-y-6">
          
          <!-- Video Preview -->
          <div class="bg-gray-800 rounded-lg p-6">
            <h2 class="text-xl font-semibold mb-4 text-blue-300">Preview</h2>
            
            <div v-if="(videoUrl && videoUrl.length > 0) || uploadedFile" class="aspect-video bg-black rounded-lg overflow-hidden">
              <video 
                v-if="previewVideoUrl"
                :src="previewVideoUrl" 
                controls 
                class="w-full h-full object-contain"
              >
                Your browser does not support the video tag.
              </video>
              <div v-else class="flex items-center justify-center h-full text-gray-400">
                <svg class="w-16 h-16" fill="currentColor" viewBox="0 0 20 20">
                  <path d="M2 6a2 2 0 012-2h6l2 2h6a2 2 0 012 2v6a2 2 0 01-2 2H4a2 2 0 01-2-2V6z" />
                </svg>
              </div>
            </div>
            
            <div v-else class="aspect-video bg-gray-700 rounded-lg flex items-center justify-center">
              <div class="text-center text-gray-400">
                <svg class="mx-auto h-16 w-16 mb-4" fill="currentColor" viewBox="0 0 20 20">
                  <path d="M2 6a2 2 0 012-2h6l2 2h6a2 2 0 012 2v6a2 2 0 01-2 2H4a2 2 0 01-2-2V6z" />
                </svg>
                <p>Video preview will appear here</p>
              </div>
            </div>
          </div>

          <!-- Progress Indicator -->
          <div v-if="isProcessing" class="bg-gray-800 rounded-lg p-6">
            <h3 class="text-lg font-semibold mb-4">Processing Progress</h3>
            
            <!-- Overall Progress Bar -->
            <div v-if="isProcessingVideo" class="mb-6">
              <div class="flex items-center justify-between mb-2">
                <span class="text-sm font-medium text-blue-300">Video Processing Progress</span>
                <span class="text-sm font-medium text-blue-300">{{ videoProcessingProgress }}%</span>
              </div>
              <div class="w-full bg-gray-700 rounded-full h-3">
                <div class="bg-gradient-to-r from-blue-500 to-purple-500 h-3 rounded-full transition-all duration-300 ease-out" 
                     :style="{ width: videoProcessingProgress + '%' }"></div>
              </div>
              <div v-if="currentProcessingStage" class="mt-2 text-xs text-gray-400">
                {{ currentProcessingStage }}
              </div>
            </div>
            
            <!-- Step by Step Progress -->
            <div class="space-y-4">
              <div v-for="step in processingSteps" :key="step.id" class="flex items-center space-x-3">
                <div class="flex-shrink-0">
                  <div v-if="step.status === 'completed'" class="w-6 h-6 bg-green-500 rounded-full flex items-center justify-center">
                    <svg class="w-4 h-4 text-white" fill="currentColor" viewBox="0 0 20 20">
                      <path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd" />
                    </svg>
                  </div>
                  <div v-else-if="step.status === 'processing'" class="w-6 h-6 border-2 border-blue-500 border-t-transparent rounded-full animate-spin"></div>
                  <div v-else class="w-6 h-6 bg-gray-600 rounded-full"></div>
                </div>
                <div class="flex-1">
                  <p class="text-sm font-medium" :class="step.status === 'completed' ? 'text-green-400' : step.status === 'processing' ? 'text-blue-400' : 'text-gray-400'">
                    {{ step.name }}
                  </p>
                  <p v-if="step.description" class="text-xs text-gray-500">{{ step.description }}</p>
                </div>
              </div>
            </div>
          </div>

          <!-- Results -->
          <div v-if="results.transcription || results.processedVideo" class="bg-gray-800 rounded-lg p-6">
            <h3 class="text-lg font-semibold mb-4">Results</h3>
            
            <!-- Transcription Result -->
            <div v-if="results.transcription" class="mb-6">
              <div class="flex items-center justify-between mb-2">
                <h4 class="text-md font-medium text-green-400">Generated SRT Subtitles</h4>
                <span class="text-xs text-gray-400">‚úèÔ∏è Editable - Make changes if needed</span>
              </div>
              
              <!-- Editable SRT Content -->
              <div class="mb-3">
                <textarea 
                  v-model="results.transcription"
                  class="w-full h-40 px-3 py-2 bg-gray-700 border border-gray-600 rounded-md text-sm text-gray-100 font-mono resize-y focus:ring-2 focus:ring-blue-500 focus:border-transparent"
                  placeholder="SRT content will appear here..."
                  spellcheck="false"
                ></textarea>
                <p class="text-xs text-gray-400 mt-1">
                  üí° You can edit the subtitles above. Format: SRT (Sequence number, timestamps, text)
                </p>
              </div>
              
              <div class="flex flex-wrap gap-2">
                <button @click="downloadTranscription" class="px-3 py-1 bg-blue-600 hover:bg-blue-700 rounded text-sm">
                  üì• Download SRT
                </button>
                <button @click="copyTranscription" class="px-3 py-1 bg-gray-600 hover:bg-gray-700 rounded text-sm">
                  üìã Copy to Clipboard
                </button>
                <button @click="validateSRT" class="px-3 py-1 bg-purple-600 hover:bg-purple-700 rounded text-sm">
                  ‚úÖ Validate SRT
                </button>
                <button @click="resetTranscription" class="px-3 py-1 bg-red-600 hover:bg-red-700 rounded text-sm">
                  üîÑ Re-generate
                </button>
              </div>
            </div>

            <!-- Processed Video Result -->
            <div v-if="results.processedVideo" class="mb-6">
              <h4 class="text-md font-medium mb-2 text-green-400">Video Processing Complete</h4>
              <div class="aspect-video bg-black rounded-lg overflow-hidden mb-2">
                <video :src="results.processedVideo" controls class="w-full h-full object-contain">
                  Your browser does not support the video tag.
                </video>
              </div>
              <div class="flex space-x-2">
                <button @click="downloadProcessedVideo" class="px-3 py-1 bg-green-600 hover:bg-green-700 rounded text-sm">
                  Download Video
                </button>
                <button v-if="results.subtitleFile" @click="downloadSubtitles" class="px-3 py-1 bg-purple-600 hover:bg-purple-700 rounded text-sm">
                  Download Subtitles
                </button>
              </div>
            </div>
          </div>

          <!-- Error Display -->
          <div v-if="error" class="bg-red-900 border border-red-700 rounded-lg p-4">
            <h4 class="text-red-400 font-medium mb-2">Error</h4>
            <p class="text-red-300 text-sm">{{ error }}</p>
            <button @click="clearError" class="mt-2 px-3 py-1 bg-red-700 hover:bg-red-800 rounded text-sm">
              Dismiss
            </button>
          </div>
        </div>
      </div>
    </main>
  </div>
</template>

<script setup>
import { ref, computed, watch, nextTick, onMounted } from 'vue'

// Set page title
useHead({
  title: 'Complete Processing - Video Processing Suite'
})

// Reactive data - declared first to avoid initialization issues
const videoUrl = ref('')
const uploadedFile = ref(null)
const previewVideoUrl = ref('')

// Debug initialization
console.log('üöÄ Component initializing, videoUrl ref:', videoUrl)

const transcriptionSettings = ref({
  source: 'video-audio',
  language: 'en',
  outputFormat: 'srt',
  speakerLabels: false,
  punctuate: true,
  formatText: true,
  manualText: ''
})

// Template configurations with exact predefined parameters
const templateConfigurations = {
  girlboss: {
    fontFamily: 'Luckiest Guy',
    primaryColor: '#FF1493',
    secondaryColor: '#FF69B4',
    fontSize: 32,
    wordMode: 'multiple',
    wordsPerGroup: 2,
    verticalPosition: 'bottom'
  },
  hormozi: {
    fontFamily: 'Luckiest Guy',
    primaryColor: '#00FF00',
    secondaryColor: '#FF0000',
    fontSize: 50,
    wordMode: 'multiple',
    wordsPerGroup: 4,
    verticalPosition: 'bottom'
  },
  tiktokstyle: {
    fontFamily: 'Luckiest Guy',
    primaryColor: '#FFFF00',
    secondaryColor: '#25F4EE',
    fontSize: 50,
    wordMode: 'multiple',
    wordsPerGroup: 2,
    verticalPosition: 'bottom'
  },
  whiteimpact: {
    fontFamily: 'Impact',
    primaryColor: '#FFFFFF',
    secondaryColor: '#E5E7EB',
    fontSize: 48,
    wordMode: 'single',
    wordsPerGroup: 1,
    verticalPosition: 'center'
  },
  impactfull: {
    fontFamily: 'Impact',
    primaryColor: '#FFFFFF',
    secondaryColor: '#E5E7EB',
    fontSize: 42,
    wordMode: 'normal',
    wordsPerGroup: 1,
    verticalPosition: 'center'
  },
  thinToBold: {
    fontFamily: 'Montserrat Thin',
    primaryColor: '#FFFFFF',
    secondaryColor: '#E5E7EB',
    fontSize: 50,
    wordMode: 'normal',
    wordsPerGroup: 4,
    verticalPosition: 'top'
  },
  wavyColors: {
    fontFamily: 'Luckiest Guy',
    primaryColor: '#FF0000',
    secondaryColor: '#00FF00',
    fontSize: 50,
    wordMode: 'multiple',
    wordsPerGroup: 1,
    verticalPosition: 'center'
  },
  revealEnlarge: {
    fontFamily: 'Luckiest Guy',
    primaryColor: '#FF0000',
    secondaryColor: '#00FF00',
    fontSize: 50,
    wordMode: 'multiple',
    wordsPerGroup: 4,
    verticalPosition: 'bottom'
  },
  shrinkingPairs: {
    fontFamily: 'Luckiest Guy',
    primaryColor: '#FFFFFF',
    secondaryColor: '#E5E7EB',
    fontSize: 36,
    wordMode: 'multiple',
    wordsPerGroup: 4,
    verticalPosition: 'center'
  }
}

const subtitleSettings = ref({
  animationStyle: 'girlboss',
  fontFamily: 'Luckiest Guy',
  primaryColor: '#FF1493',
  secondaryColor: '#FF69B4',
  fontSize: 32,
  wordMode: 'multiple',
  wordsPerGroup: 2,
  verticalPosition: 'bottom'
})

const processingOptions = ref({
  generateSubtitles: true,
  embedSubtitles: true,
  optimizeForWeb: true,
  quality: 'premium'
})

const isTranscribing = ref(false)
const isProcessingVideo = ref(false)
const videoProcessingProgress = ref(0)
const currentProcessingStage = ref('')
const error = ref('')

const results = ref({
  transcription: '',
  processedVideo: '',
  subtitleFile: '',
  videoBlob: null
})

const processingSteps = ref([
  { id: 1, name: 'Preparing video', description: 'Uploading and validating video source', status: 'pending' },
  { id: 2, name: 'Audio extraction', description: 'Extracting audio track from video', status: 'pending' },
  { id: 3, name: 'AI transcription', description: 'Converting speech to text using AI', status: 'pending' },
  { id: 4, name: 'Subtitle styling', description: 'Applying animations and formatting', status: 'pending' },
  { id: 5, name: 'Video processing', description: 'Embedding subtitles and finalizing', status: 'pending' }
])

// Computed properties - defined after all reactive variables
const isProcessing = computed(() => {
  return isTranscribing.value || isProcessingVideo.value
})

const canStartTranscription = computed(() => {
  if (transcriptionSettings.value.source === 'manual') {
    return transcriptionSettings.value.manualText.trim().length > 0 && !isProcessing.value
  }
  return (videoUrl?.value || uploadedFile.value) && !isProcessing.value
})

const canProcessVideo = computed(() => {
  const hasVideo = videoUrl?.value || uploadedFile.value
  const hasTranscription = results.value.transcription && results.value.transcription.trim().length > 0
  return hasVideo && hasTranscription && !isProcessing.value
})

// Template system computed properties (all templates are now editable presets)
const isUsingPredefinedTemplate = computed(() => {
  return false // All templates are now editable presets with suggested values
})

const currentTemplateConfig = computed(() => {
  return templateConfigurations[subtitleSettings.value.animationStyle] || null
})

// Template information functions
const getTemplateDescription = (template) => {
  const descriptions = {
    'girlboss': 'Bold pink/purple animations with dramatic emphasis and confidence vibes',
    'hormozi': 'Business motivational style with professional color schemes and impact',
    'tiktokstyle': 'Social media trending format with engaging visual effects',
    'whiteimpact': 'Clean white highlights with sharp contrast and professional look',
    'impactfull': 'Maximum visual impact with bold animations and attention-grabbing effects',
    'thinToBold': 'Progressive text emphasis that grows from thin to bold for key moments',
    'wavyColors': 'Flowing rainbow effects with smooth color transitions and wave motions',
    'revealEnlarge': 'Zoom-in discovery effects that reveal text with enlarging animations',
    'shrinkingPairs': 'Minimalist paired animations with clean shrinking transitions'
  }
  return descriptions[template] || 'Custom animation template'
}

const getTemplateFeatures = (template) => {
  const features = {
    'girlboss': '‚ú® Pink/purple gradients ‚Ä¢ Bold typography ‚Ä¢ Confidence themes',
    'hormozi': 'üéØ Business colors ‚Ä¢ Motivational emphasis ‚Ä¢ Professional appeal',
    'tiktokstyle': 'üì± Trending effects ‚Ä¢ Social engagement ‚Ä¢ Mobile-optimized',
    'whiteimpact': '‚ö™ White highlights ‚Ä¢ Clean design ‚Ä¢ High contrast',
    'impactfull': 'üí• Maximum impact ‚Ä¢ Bold effects ‚Ä¢ Attention-grabbing',
    'thinToBold': 'üìà Progressive weight ‚Ä¢ Dynamic emphasis ‚Ä¢ Smooth transitions',
    'wavyColors': 'üåà Rainbow effects ‚Ä¢ Flowing motion ‚Ä¢ Color waves',
    'revealEnlarge': 'üîç Zoom reveals ‚Ä¢ Discovery effects ‚Ä¢ Enlarging text',
    'shrinkingPairs': 'üìê Paired elements ‚Ä¢ Minimalist design ‚Ä¢ Shrinking effects'
  }
  return features[template] || 'Custom features and animations'
}

// Template color schemes
const getTemplateColors = (template) => {
  const colorSchemes = {
    'girlboss': { primary: '#ff1493', secondary: '#ff69b4' }, // Deep pink, hot pink
    'hormozi': { primary: '#1e40af', secondary: '#f59e0b' }, // Blue, amber  
    'tiktokstyle': { primary: '#fe2c55', secondary: '#25f4ee' }, // TikTok red, cyan
    'whiteimpact': { primary: '#ffffff', secondary: '#e5e7eb' }, // White, light gray
    'impactfull': { primary: '#dc2626', secondary: '#fbbf24' }, // Red, yellow
    'thinToBold': { primary: '#3b82f6', secondary: '#8b5cf6' }, // Blue, purple
    'wavyColors': { primary: '#06b6d4', secondary: '#f59e0b' }, // Cyan, amber
    'revealEnlarge': { primary: '#10b981', secondary: '#3b82f6' }, // Green, blue
    'shrinkingPairs': { primary: '#6b7280', secondary: '#9ca3af' } // Gray, light gray
  }
  return colorSchemes[template] || { primary: '#3b82f6', secondary: '#10b981' }
}

// Methods
const handleFileUpload = (event) => {
  const file = event.target.files[0]
  if (file) {
    uploadedFile.value = file
    previewVideoUrl.value = URL.createObjectURL(file)
    if (videoUrl && videoUrl.value !== undefined) {
      videoUrl.value = '' // Clear URL if file is uploaded
    }
  }
}

// Apply predefined template settings automatically
const applyTemplateSettings = (templateName) => {
  const templateConfig = templateConfigurations[templateName]
  if (templateConfig) {
    console.log(`üé® Applying predefined ${templateName} template settings:`, templateConfig)
    
    // Apply all template-specific settings
    subtitleSettings.value.fontFamily = templateConfig.fontFamily
    subtitleSettings.value.primaryColor = templateConfig.primaryColor
    subtitleSettings.value.secondaryColor = templateConfig.secondaryColor
    subtitleSettings.value.fontSize = templateConfig.fontSize
    subtitleSettings.value.wordMode = templateConfig.wordMode
    subtitleSettings.value.wordsPerGroup = templateConfig.wordsPerGroup
    subtitleSettings.value.verticalPosition = templateConfig.verticalPosition
  }
}

// Legacy function for manual color application (now unused)
const applyTemplateColors = () => {
  const colors = getTemplateColors(subtitleSettings.value.animationStyle)
  subtitleSettings.value.primaryColor = colors.primary
  subtitleSettings.value.secondaryColor = colors.secondary
}

// Get optimal word processing mode for each template
const getTemplateWordMode = (template) => {
  const wordModeSettings = {
    'girlboss': 'multiple',        // Works well with 2-3 words at a time for emphasis
    'hormozi': 'single',           // Best with individual word highlighting
    'tiktokstyle': 'single',       // TikTok style emphasizes individual words
    'whiteimpact': 'single',       // White impact designed for word-by-word reveals
    'impactfull': 'single',        // Maximum impact with individual words
    'thinToBold': 'single',        // Progressive weight change works per word
    'wavyColors': 'single',        // Wavy animations work best word-by-word
    'revealEnlarge': 'multiple',   // Revealing groups of words creates better flow
    'shrinkingPairs': 'multiple'   // Pairs work better with multiple words
  }
  return wordModeSettings[template] || 'normal'
}

// Get optimal words per group for templates using 'multiple' mode
const getTemplateWordsPerGroup = (template) => {
  const wordsPerGroupSettings = {
    'girlboss': 2,           // 2 words for confident emphasis
    'hormozi': 1,            // Single words for business impact
    'tiktokstyle': 1,        // Individual words for viral effect
    'whiteimpact': 1,        // Single words for clean impact
    'impactfull': 1,         // Single words for maximum impact
    'thinToBold': 1,         // Progressive effect per word
    'wavyColors': 1,         // Wavy effect per word
    'revealEnlarge': 3,      // 3 words for smooth reveals
    'shrinkingPairs': 2      // Pairs of words
  }
  return wordsPerGroupSettings[template] || 1
}

// Get description of template's optimal word mode
const getTemplateWordModeDescription = (template) => {
  const wordMode = getTemplateWordMode(template)
  const wordsPerGroup = getTemplateWordsPerGroup(template)
  
  const descriptions = {
    'girlboss': `Multiple words (${wordsPerGroup} at a time) for confident emphasis`,
    'hormozi': 'Single words for maximum business impact',
    'tiktokstyle': 'Single words for viral TikTok-style effect',
    'whiteimpact': 'Single words with clean white reveals',
    'impactfull': 'Single words for maximum visual impact',
    'thinToBold': 'Single words with progressive weight changes',
    'wavyColors': 'Single words with flowing color waves',
    'revealEnlarge': `Multiple words (${wordsPerGroup} at a time) for smooth reveals`,
    'shrinkingPairs': `Word pairs (${wordsPerGroup} words) for minimalist effect`
  }
  
  return descriptions[template] || 'Standard sentence-based timing'
}

// Apply template's optimal word processing settings
const applyTemplateWordSettings = () => {
  subtitleSettings.value.wordMode = getTemplateWordMode(subtitleSettings.value.animationStyle)
  subtitleSettings.value.wordsPerGroup = getTemplateWordsPerGroup(subtitleSettings.value.animationStyle)
}

const updateProcessingStep = (stepId, status, description = null) => {
  const step = processingSteps.value.find(s => s.id === stepId)
  if (step) {
    step.status = status
    if (description) step.description = description
  }
}

const resetProcessingSteps = () => {
  processingSteps.value.forEach(step => {
    step.status = 'pending'
  })
}

const startTranscription = async () => {
  if (!canStartTranscription.value) return

  console.log('‚úÖ Starting transcription process...')
  isTranscribing.value = true
  error.value = ''
  resetProcessingSteps()

  try {
    updateProcessingStep(1, 'processing')
    console.log('üé¨ Video URL:', videoUrl?.value || 'Not set')
    
    // Handle manual transcription
    if (transcriptionSettings.value.source === 'manual') {
      updateProcessingStep(1, 'completed', 'Manual transcription selected')
      updateProcessingStep(2, 'completed', 'Skipping audio extraction')
      updateProcessingStep(3, 'processing', 'Processing manual transcription...')
      
      // Use manual transcription directly
      results.value.transcription = transcriptionSettings.value.manualText
      updateProcessingStep(3, 'completed')
      updateProcessingStep(4, 'completed', 'Ready for styling')
      updateProcessingStep(5, 'completed', 'Transcription complete')
      return
    }

    // Handle video audio transcription
    let processVideoUrl = videoUrl?.value || ''
    if (!processVideoUrl && !uploadedFile.value) {
      throw new Error('No video URL or file provided')
    }
    updateProcessingStep(1, 'completed', 'Video source validated')
    
    if (uploadedFile.value) {
      // For file uploads, we need to process the audio extraction
      updateProcessingStep(2, 'processing', 'Extracting audio from uploaded video...')
      
      // Call audio extraction API
      const audioResponse = await $fetch('/api/extract-audio', {
        method: 'POST',
        body: {
          videoFile: uploadedFile.value
        }
      })
      
      processVideoUrl = audioResponse.audioUrl
      updateProcessingStep(2, 'completed', 'Audio track extracted successfully')
    } else {
      updateProcessingStep(2, 'processing', 'Preparing video URL for audio extraction...')
      updateProcessingStep(2, 'completed', 'Video URL ready for transcription')
    }

    updateProcessingStep(3, 'processing', 'Transcribing audio with AssemblyAI...')

    // First test basic API connectivity
    console.log('üîç Testing basic API connectivity...')
    try {
      const testResponse = await $fetch('/api/test', { method: 'GET' })
      console.log('‚úÖ Basic API connectivity confirmed:', testResponse)
    } catch (testError) {
      console.error('‚ùå Basic API test failed:', testError)
      error.value = 'API connectivity issue: ' + testError.message
      return
    }

    console.log('ü§ñ Making transcription API call with:', {
      url: processVideoUrl,
      language: transcriptionSettings.value.language,
      outputFormat: transcriptionSettings.value.outputFormat
    })

    // Call transcription API with explicit error handling
    const response = await $fetch('/api/transcribe-video', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: {
        url: processVideoUrl,
        language: transcriptionSettings.value.language,
        outputFormat: transcriptionSettings.value.outputFormat,
        speakerLabels: transcriptionSettings.value.speakerLabels,
        punctuate: transcriptionSettings.value.punctuate,
        formatText: transcriptionSettings.value.formatText
      },
      timeout: 300000 // 5 minutes timeout for transcription
    }).catch((fetchError) => {
      console.error('üö® API Fetch Error:', fetchError)
      throw new Error(`API request failed: ${fetchError.message || fetchError}`)
    })

    console.log('‚úÖ Transcription API response:', response)

    updateProcessingStep(3, 'completed', 'Speech-to-text conversion complete')
    updateProcessingStep(4, 'completed', 'Ready for subtitle styling')
    updateProcessingStep(5, 'completed', 'Transcription process finished')

    if (response.transcription) {
      console.log('üìù Setting transcription in results:', {
        before: results.value.transcription?.length || 0,
        after: response.transcription.length
      })
      results.value.transcription = response.transcription
      console.log('üìù Transcription saved successfully')
      console.log('üéØ Current results state:', {
        hasTranscription: !!results.value.transcription,
        transcriptionLength: results.value.transcription?.length || 0,
        transcriptionPreview: results.value.transcription?.substring(0, 100) || 'EMPTY'
      })
    } else {
      console.warn('‚ö†Ô∏è No transcription in response:', response)
      error.value = 'No transcription received from API'
    }

  } catch (err) {
    console.error('‚ùå Transcription error:', err)
    error.value = err.message || err.data?.message || 'Transcription failed'
    resetProcessingSteps()
    
    // Show more detailed error info
    if (err.data) {
      console.error('Error details:', err.data)
    }
  } finally {
    isTranscribing.value = false
  }
}

const processVideo = async () => {
  if (!canProcessVideo.value) return

  isProcessingVideo.value = true
  error.value = ''
  resetProcessingSteps()

  try {
    updateProcessingStep(1, 'processing')
    
    // Prepare the video URL
    let processVideoUrl = videoUrl?.value || ''
    if (uploadedFile.value) {
      throw new Error('File upload not yet implemented. Please use a video URL.')
    }
    
    if (!processVideoUrl) {
      throw new Error('No video URL provided')
    }

    updateProcessingStep(1, 'completed')

    // If no transcription exists, do transcription first
    if (!results.value.transcription) {
      updateProcessingStep(2, 'processing')
      
      const transcriptionResponse = await $fetch('/api/transcribe-video', {
        method: 'POST',
        body: {
          url: processVideoUrl,
          outputFormat: 'json',
          language: transcriptionSettings.value.language
        }
      })

      updateProcessingStep(2, 'completed')
      results.value.transcription = transcriptionResponse.transcription
    } else {
      updateProcessingStep(2, 'completed', 'Using existing transcription')
    }

    updateProcessingStep(3, 'processing', 'Creating styled subtitles...')

    // Debug logging
    console.log('Processing video with transcription:', {
      transcriptionLength: results.value.transcription?.length || 0,
      transcriptionPreview: results.value.transcription?.substring(0, 100) || 'No transcription',
      template: subtitleSettings.value.animationStyle
    })

    // Start realistic progress tracking
    videoProcessingProgress.value = 0
    currentProcessingStage.value = 'Initializing video processing...'
    
    // Realistic progress simulation that mimics actual video processing
    let progressStage = 0
    let progressInterval = null
    const progressStages = [
      { maxProgress: 15, duration: 2000, increment: 0.8, stage: 'Initializing FFmpeg and loading video...' },
      { maxProgress: 25, duration: 3000, increment: 0.6, stage: 'Analyzing video metadata and streams...' },
      { maxProgress: 40, duration: 4000, increment: 0.7, stage: 'Preparing ' + subtitleSettings.value.animationStyle + ' animation template...' },
      { maxProgress: 65, duration: 8000, increment: 0.5, stage: 'Rendering subtitles with ' + processingOptions.value.quality + ' quality...' },
      { maxProgress: 85, duration: 6000, increment: 0.6, stage: 'Encoding video with embedded subtitles...' },
      { maxProgress: 92, duration: 3000, increment: 0.4, stage: 'Finalizing output and compression...' }
    ]
    
    progressInterval = setInterval(() => {
      if (progressStage < progressStages.length) {
        const currentStage = progressStages[progressStage]
        
        if (videoProcessingProgress.value < currentStage.maxProgress) {
          videoProcessingProgress.value = Math.min(
            videoProcessingProgress.value + currentStage.increment + (Math.random() * 0.4), 
            currentStage.maxProgress
          )
          currentProcessingStage.value = currentStage.stage
        } else {
          progressStage++
        }
      }
    }, 1000)

    // Call video processing API and get binary response
    console.log('üé¨ Making video processing request...')
    const response = await fetch('/api/process-video', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        videoUrl: processVideoUrl,
        template: subtitleSettings.value.animationStyle,
        transcription: results.value.transcription,
        fontFamily: subtitleSettings.value.fontFamily,
        primaryColor: subtitleSettings.value.primaryColor,
        secondaryColor: subtitleSettings.value.secondaryColor,
        fontSize: subtitleSettings.value.fontSize,
        verticalPosition: subtitleSettings.value.verticalPosition,
        embedSubtitles: processingOptions.value.embedSubtitles,
        generateSubtitles: processingOptions.value.generateSubtitles,
        quality: processingOptions.value.quality,
        // Word processing settings
        wordMode: subtitleSettings.value.wordMode,
        wordsPerGroup: subtitleSettings.value.wordsPerGroup
      })
    })

    console.log('üì° Video processing response status:', response.status)
    
    // Clear progress interval
    clearInterval(progressInterval)
    
    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`Video processing failed: ${errorText}`)
    }

    updateProcessingStep(3, 'completed')
    updateProcessingStep(4, 'processing', 'Downloading processed video...')

    // Smoothly progress to near completion
    videoProcessingProgress.value = Math.max(videoProcessingProgress.value, 95)
    currentProcessingStage.value = 'Downloading processed video...'

    // Get the video blob
    const videoBlob = await response.blob()
    console.log('üìπ Video blob received:', {
      size: videoBlob.size,
      type: videoBlob.type
    })

    // Create object URL for the video
    const processedVideoUrl = URL.createObjectURL(videoBlob)
    results.value.processedVideo = processedVideoUrl
    results.value.videoBlob = videoBlob // Store blob for download

    updateProcessingStep(4, 'completed')
    updateProcessingStep(5, 'completed', 'Ready for download')
    
    // Finalize progress
    videoProcessingProgress.value = 100
    currentProcessingStage.value = 'Processing complete!'

  } catch (err) {
    error.value = err.message || 'Video processing failed'
    resetProcessingSteps()
  } finally {
    // Always clear progress interval
    if (progressInterval) {
      clearInterval(progressInterval)
      progressInterval = null
    }
    isProcessingVideo.value = false
    // Reset progress after a delay
    setTimeout(() => {
      videoProcessingProgress.value = 0
      currentProcessingStage.value = ''
    }, 3000)
  }
}

const downloadTranscription = () => {
  if (!results.value.transcription) return

  const blob = new Blob([results.value.transcription], { type: 'text/plain' })
  const url = URL.createObjectURL(blob)
  const a = document.createElement('a')
  a.href = url
  a.download = `transcription.${transcriptionSettings.value.outputFormat}`
  document.body.appendChild(a)
  a.click()
  document.body.removeChild(a)
  URL.revokeObjectURL(url)
}

const copyTranscription = async () => {
  if (!results.value.transcription) return

  try {
    await navigator.clipboard.writeText(results.value.transcription)
    // You could show a toast notification here
  } catch (err) {
    console.error('Failed to copy transcription:', err)
  }
}

const downloadProcessedVideo = () => {
  if (!results.value.processedVideo || !results.value.videoBlob) return

  console.log('‚¨áÔ∏è Downloading processed video:', {
    blobSize: results.value.videoBlob.size,
    blobType: results.value.videoBlob.type
  })

  const a = document.createElement('a')
  a.href = results.value.processedVideo // This is the object URL
  a.download = 'processed-video.mp4'
  document.body.appendChild(a)
  a.click()
  document.body.removeChild(a)
}

const downloadSubtitles = () => {
  if (!results.value.subtitleFile) return

  const a = document.createElement('a')
  a.href = results.value.subtitleFile
  a.download = 'subtitles.srt'
  document.body.appendChild(a)
  a.click()
  document.body.removeChild(a)
}

const clearError = () => {
  error.value = ''
}

const validateSRT = () => {
  if (!results.value.transcription) {
    alert('No SRT content to validate!')
    return
  }

  // Basic SRT validation
  const lines = results.value.transcription.trim().split('\n')
  let isValid = true
  let errorMessage = ''

  try {
    let currentBlock = 1
    let i = 0
    
    while (i < lines.length) {
      // Skip empty lines
      if (!lines[i].trim()) {
        i++
        continue
      }
      
      // Check sequence number
      if (parseInt(lines[i]) !== currentBlock) {
        isValid = false
        errorMessage = `Invalid sequence number at line ${i + 1}. Expected ${currentBlock}, got ${lines[i]}`
        break
      }
      
      i++
      if (i >= lines.length) break
      
      // Check timestamp format
      const timeRegex = /^\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}$/
      if (!timeRegex.test(lines[i])) {
        isValid = false
        errorMessage = `Invalid timestamp format at line ${i + 1}: ${lines[i]}`
        break
      }
      
      i++
      currentBlock++
      
      // Skip text lines until next empty line or end
      while (i < lines.length && lines[i].trim()) {
        i++
      }
    }
    
    if (isValid) {
      alert(`‚úÖ SRT is valid! Found ${currentBlock - 1} subtitle blocks.`)
    } else {
      alert(`‚ùå SRT validation failed: ${errorMessage}`)
    }
    
  } catch (err) {
    alert(`‚ùå SRT validation error: ${err.message}`)
  }
}

const resetTranscription = async () => {
  if (confirm('Are you sure you want to re-generate the transcription? This will overwrite your current edits.')) {
    results.value.transcription = ''
    await startTranscription()
  }
}

const testTranscription = () => {
  console.log('üß™ Testing transcription display...')
  const testSRT = `1
00:00:00,000 --> 00:00:03,000
This is a test subtitle

2
00:00:03,000 --> 00:00:06,000
To see if the display works

3
00:00:06,000 --> 00:00:09,000
The UI should update now!`
  
  results.value.transcription = testSRT
  console.log('üß™ Test transcription set:', testSRT.length, 'characters')
}

const testAPI = async () => {
  console.log('üß™ Testing API connectivity...')
  
  try {
    // Test GET request
    const getResponse = await $fetch('/api/test', {
      method: 'GET'
    })
    console.log('‚úÖ GET test successful:', getResponse)
    
    // Test POST request  
    const postResponse = await $fetch('/api/test', {
      method: 'POST',
      body: {
        test: 'data',
        videoUrl: videoUrl?.value || '',
        timestamp: new Date().toISOString()
      }
    })
    console.log('‚úÖ POST test successful:', postResponse)
    
    alert('API tests passed! Check console for details.')
    
  } catch (error) {
    console.error('‚ùå API test failed:', error)
    alert(`API test failed: ${error.message}`)
  }
}

// Initialize watchers after component is mounted to avoid initialization issues
onMounted(() => {
  console.log('‚úÖ Component mounted, setting up watchers')
  
  // Initialize optimal word processing settings for default template
  applyTemplateWordSettings()
  
  // Watch for video URL changes to update preview
  watch(() => videoUrl.value, (newUrl) => {
    console.log('üîÑ VideoURL changed:', newUrl)
    if (newUrl && !uploadedFile?.value) {
      previewVideoUrl.value = newUrl
    }
  }, { immediate: false })

  // Watch for transcription changes (debugging)
  watch(() => results.value.transcription, (newTranscription, oldTranscription) => {
    console.log('üëÄ Transcription watcher triggered:', {
      hadBefore: !!oldTranscription,
      hasNow: !!newTranscription,
      lengthBefore: oldTranscription?.length || 0,
      lengthNow: newTranscription?.length || 0,
      preview: newTranscription?.substring(0, 50) || 'EMPTY'
    })
  })

  // Watch for template changes to apply predefined settings automatically
  watch(() => subtitleSettings.value.animationStyle, (newTemplate, oldTemplate) => {
    if (newTemplate !== oldTemplate) {
      console.log('üé® Template changed to:', newTemplate)
      // Apply complete predefined template settings (colors, fonts, word processing)
      applyTemplateSettings(newTemplate)
    }
  }, { immediate: true }) // Apply settings immediately on component mount
})
</script>

<style scoped>
/* Additional custom styles if needed */
</style>